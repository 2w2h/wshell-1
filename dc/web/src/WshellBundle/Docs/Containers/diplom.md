# Безопасное выполнение произвольного программного кода в распределенной вычислительной сети.

## Введение

Современные задачи в области обработки данных требуют выполнения множества обязательных условий:
быстрое получение результата, гибкость работы с данными разной структуры и объема, доступность
и удобство с точки зрения пользователей. Не менее важной задачей является построение
правильной архитектуры программного продукта для развития и поддержки со стороны разработчиков.

Правильное использование абстракций при разработке даёт возможность не акцентироваться на конкретных задачах
обработки данных, а делегировать их на уровень использования программным продуктом. Другими словами,
при появлении новой задачи, будь то перекодирование видео, шифрование персональных данных или
сбор статистики по некоторому набору данных, нет необходимости в разработке программного кода с нуля,
достаточно определиться с тем, к какому уровню абстракции относиться нужный функционал и возможно ли решить
задачу с наименьшими усилиями при уже существующих вычислительных ресурсах. Этот подход хорошо зарекомендовал себя во множестве сфер применения информационных технологий и является одим из важнейших принципов при разработке современного ПО.

Доступность использования также является важной составляющей для вычислительной сети. Благодаря быстрому развитию
информационных технологий в области передачи цифровых данных, особенно на базе сети Интернет, стало существенно
проще решать типичные пользовательские задачи в режиме "сервиса", т.е. без локальной установки специализированного ПО,
а также унифицировать множество различных телекоммуникационных услуг, до этого момента имевших совершенно
разнородную реализацию. Наиболее распространенная архитектура сервисов на базе стека TCP/IP - архитектура вида "клиент-сервер". При всей своей простоте она позволила очень эффективно использовать ресурсы одной вычислительной машины, однако,
являясь самым простым способом сетевого взаимодействия, для ряда вычислительных задач всё же не подходит.
Основной её недостаток в отстутствии т.н. горизонтального маштабирования, или другими словами отсутствии возможности наращивания вычислительных мощностей путём включения в вычислительную сеть новых узлов.
Существуют обходы этой проблемы в виде использования прокси-серверов, скрывающих за собой вычислительную
сеть, но данное решение не является гибким по двум причинам: во-первых, добавление новых или замена
существующих узлов сети требует ручной переконфигурации прокси-сервера, во-вторых, вычислительные ресурсы
статичны и независимы от текущих требований, что влечёт за собой типичную проблему простоя оборудования.

Именно поэтому в течении последнего десятилетия начали появляться т.н. облачные вычислительные сети и облачные хранилища. Они также имеют единую точку входа (например, тот же прокси-сервер), но при этом лишены
недостатков, упомянутых выше, за счет использования одноранговых сетей в своей инфраструктуре.

2006г - запуск Elastic Computing Cloud (EC2) компанией Amazon. Впервые используются термины "cloud", "cloud computing".
2007г - японская компания Heroku создала одноименный сервис, ставший первой полноценной PaaS-платформой
2009г - Google запускает сервис Google Apps
2011г - Национальный институт стандартов и технологий США (NIST) стандартизировал набор понятий и требований,
применимых к облачным сетям.
2014г - российская комания Yandex запускает PaaS платформу Cocaine

На данный момент рынок облачных технологий имеет большое разнообразие как в способе предоставления услуг
(IaaS, PaaS, SaaS) так и по виду использования (общедоступные, корпоративные, гибридные). Однако при этом
существует очень мало решений, расчитанных на свободное пользование, что могло бы пригодиться для множества
предприятий с большим объемом автоматизируемых задач или, например, решений ориентированных на учебный процесс. Также, в первую очередь из-за закрытой реализации, нет облачных сетей с возможностью расширения
за счёт пользовательских ресурсов, что могло бы дать новый виток в развитии этой технологии.

Помимо этого, неосвещенным остаётся важный вопрос безопасности: как выполнять пользовательский код (или готовое ПО) в таких сетях, не ставя под угрозу данные других пользователей и работоспособность всей сети в целом? Эта задача примечательна тем, что характерна именно для облачных сетей, однако в подавляющем
числе случаев решается, видимо, без единого подхода и без публикации в открытом доступе каких-либо
технических подробностей.

Классически, изолированное выполнение кода реализуется настройкой так называемых "sandbox"
серверов, с полной эмуляцией работы ОС ("виртуализация"). Это решение отлично подходит
для разовых задач, в том числе тестирования эксплуатации разного рода уязвимостей,
но из-за сложности администрирования и нерационального использования ресурсов непригодно
для бизнес задач. Поэтому сейчас наиболее приемлемым вариантом является использование
технологии "контейнеризации" - она существенно эффективнее, дешевле и удобнее в плане
администрирования.

Подводя итог вышесказанному, тема данной дипломной работы (распределенные вычислительной сети  с облачной моделью и использованием изолированных контейнеров) представляется весьма актуальной и важной для дальнейшего исследования вопросов безопасности таких сетей. Результатом работы является открытая и потенциально безопасная реализация SaaS облака,
которую можно будет использовать как в образовательных, так и в практических целях. Учитывая особенности
инфрастуктуры (одноранговая сеть с логическим назначением ролей) такая реализация возможна написанием
одного программного продукта, устанавливаемого на каждый из узлов сети. Основной упор в
исследовании делается на вопросах безопасности сетевого взаимодействия и выполнения произвольного пользовательского кода в этой сети.

1 Анализ существующего инструментария

1.1. Цель
Провести общий обзор стека технологий контейнеризации, существующих решений.

1.2. Ядро linux: cgroups, namespaces, chroot
1.3. Единый API: LXC и альтернативы
1.4. Docker - решение для распределённых сред выполнения (упомянуть про кроссплатформенность)

2 Разработка алгоритма программного продукта

2.1. Цель
Описать алгоритм работы программы

2.2. Общая структура программного продукта (немного о golang)
2.3. Сетевое взаимодействие
2.4. Управление контейнерами
2.5. Управление задачами
2.6. Обмен данными между контейнерами

3 Инфраструктура программного продукта

3.1 Цель
Описать процесс инсталяции, конфигурации и обслуживания программного продукта

3.3 Клиенты: web морда, desktop, браузер
3.4 Кластер: Зависимости, конфиги, заготовки контейнеров ("образы"), БД
3.5 Протокол обмена

4 БЖ

Заключение

В процессе работы было изучено
было разработано
были предложены
было проанализированно




Основная часть дипломного проекта - программа, контролирующая
выполнение произвольного программного кода в контейнерах.

Функционально программа состоит из 5 частей:

* WAMP client - получает задания и отдает ответы по сети
* scheduler - парсит задания и сохраняет их во временном файловом кеше,
устанавливает порядок выполнения, опрашивая узлы (если мастер)
* docker wrapper - обертка над функционалом docker
* czmq broker - предназначен для обмена данными между контейнерами
* core - управление всеми модулями и установка конфигурации


https://xakep.ru/2015/06/04/docker-faq/

Docker Compose - управление многоконтейнерным приложением
пример docker-compose.yml
web:
  build: .
  ports:
   - "5000:5000"
  volumes:
   - .:/code
  links:
   - redis
redis:
  image: redis

Docker Machine - просто обертка для установки Docker =)
Docker Swarm - для кластеров

https://docs.docker.com/engine/articles/dockerfile_best-practices/#the-dockerfile-instructions

google: docker containers IPC

Преимущества Docker перед LXC, OpenVZ и другими решениями виртуализации уровня ОС

Docker использует переносимый универсальный формат образов. Это означает, что эти образы могут быть без каких-либо проблем перенесены на другую машину и расшарены для использования другими юзерами.
Образ может служить базой для других образов. В Docker считается нормой использовать множество слоев для формирования конечного образа. Ты можешь начать с базового образа Ubuntu, затем добавить Apache 2.4, чтобы создать микросервис Ubuntu + Apache.
При выполнении коммита образ можно версионировать, так же как это делается в GIT.
У Docker большое комьюнити и обширная экосистема, которая включает серьезное количество инструментов масштабирования, группировки, мониторинга, разворачивания и управления контейнерами.
